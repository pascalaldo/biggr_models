#! /usr/bin/env python3

"""Load synonyms from MetaNetX MNXref namespace."""

from cobradb.models import *
from cobradb.util import get_or_create, get_or_create_data_source

from sqlalchemy import exists
from os.path import join, abspath, dirname, exists
from os import mkdir
import subprocess
from collections import defaultdict

# MetaNetX files to download
files = {
    "chem_xref": "chem_xref.tsv",
    # XREF <tab> MNX_ID <tab> Evidence <tab> Description
    # bigg:10fthf <tab> MNXM237 <tab> inferred <tab> 10-Formyltetrahydrofolate
    "chem_prop": "chem_prop.tsv",
    # MNX_ID <tab> Description <tab> Formula <tab> Charge <tab> Mass <tab> InChi <tab> SMILES <tab> Source
    "comp_xref": "comp_xref.tsv",
    # XREF <tab> MNX_ID <tab> Description
    # 'comp_prop': 'comp_prop.tsv',
    # MNX_ID <tab> Description <tab> Source
    "reac_xref": "reac_xref.tsv",
    # XREF <tab> MNX_ID
    # bigg:10FTHF5GLUtl <tab> MNXR1
    "reac_prop": "reac_prop.tsv",
    # MNX_ID <tab> Equation <tab> Description <tab> Balance <tab> EC <tab> Source
}

# translation table for MetaNetX databases to those already in BiGG Models
# see https://github.com/SBRG/bigg_models_data/blob/master/data-source-prefs.txt
db_translation = {
    "metabolite": {
        "biopath": "biopath.molecule",
        "chebi": lambda val: ("chebi", "CHEBI:%s" % val),
        "kegg": lambda val: (
            ("kegg.drug", val)
            if val.startswith("D")
            else ("kegg.glycan", val) if val.startswith("G") else ("kegg.compound", val)
        ),
        "metacyc": lambda val: ("biocyc", "META:%s" % val),
        "reactome": "reactome.compound",
        "seed": "seed.compound",
        "umbbd": "umbbd.compound",
        "upa": "unipathway.compound",
    },
    "reaction": {
        "biopath": "biopath.reaction",
        "kegg": "kegg.reaction",
        "metacyc": lambda x: ("biocyc", "META:%s" % x),
        "reactome": "reactome.reaction",
        "seed": "seed.reaction",
        "upa": "unipathway.reaction",
    },
}

# directory to store the MetaNetX files
data_dir = abspath(join(dirname(__file__), "..", "temp_data"))

# make the temp directory
try:
    mkdir(data_dir)
except OSError:
    pass


def main():
    # download the files from MetaNetX
    for key, filename in files.items():
        download_file(filename)

    # database session
    session = Session()

    # Update chemicals
    chemical_xref = parse_xref("chem_xref", "metabolite")
    chemical_xref = add_inchi_keys("chem_prop", chemical_xref)
    update_synonyms(chemical_xref, "metabolite", session)

    # Update reactions
    reaction_xref = parse_xref("reac_xref", "reaction")
    reaction_xref = add_ec_numbers("reac_prop", reaction_xref)
    update_synonyms(reaction_xref, "reaction", session)

    # Update compartments
    # TODO compartment synonyms

    print_missing_metabolite_refs(session)

    session.close()


def add_prefix(loc):
    """Add the MetaNetX url prefix."""
    return "http://www.metanetx.org/cgi-bin/mnxget/mnxref/%s" % loc.lstrip("/")


def download_file(filename):
    """Download a file to the data dir."""
    destination = join(data_dir, filename)
    if not exists(destination):
        print("Downloading %s" % filename)
        subprocess.call(["wget", "-O", destination, add_prefix(filename)])
    else:
        print("Already downloaded %s" % filename)


def update_synonyms(xref_dict, ref_type, session):
    """Use MetaNetX files to add Reaction or Metabolite synonyms."""

    warned = set()

    stats = {"found": 0, "not_found": 0}

    object_class = Reaction if ref_type == "reaction" else Component
    object_synonym_type = "reaction" if ref_type == "reaction" else "component"

    for bigg_id, ref_dict in xref_dict.items():
        # look for the metabolites
        objects_db = session.query(object_class).filter(object_class.bigg_id == bigg_id)
        if objects_db is None:
            # check old IDs
            if ref_type == "reaction":
                objects_db = (
                    session.query(object_class)
                    .join(ModelReaction)
                    .join(OldIDSynonym, OldIDSynonym.ome_id == ModelReaction.id)
                    .join(Synonym)
                    .filter(Synonym.synonym == bigg_id)
                )
            else:
                objects_db = (
                    session.query(object_class)
                    .join(CompartmentalizedComponent)
                    .join(ModelCompartmentalizedComponent)
                    .join(
                        OldIDSynonym,
                        OldIDSynonym.ome_id == ModelCompartmentalizedComponent.id,
                    )
                    .join(Synonym)
                    .filter(Synonym.synonym == bigg_id)
                )
            if objects_db.count() == 0:
                print("%s not found in database: %s" % (ref_type, bigg_id))
                continue
            # else:
            #     print(bigg_id, objects_db.first().bigg_id)

        if objects_db.count() > 1:
            print("Multiple results for %s: %s" % (ref_type, bigg_id))

        for object_db in objects_db:
            for ref, values in ref_dict.items():
                data_source_id = get_or_create_data_source(session, ref)

                for val in values:
                    # add the Synonym
                    synonym_db, exists = get_or_create(
                        session,
                        Synonym,
                        ome_id=object_db.id,
                        type=object_synonym_type,
                        data_source_id=data_source_id,
                        synonym=val,
                    )
                    if exists:
                        stats["found"] += 1
                    else:
                        stats["not_found"] += 1

    print("New %s synonyms: %d" % (ref_type, stats["not_found"]))


def add_inchi_keys(file_key, chemical_xref):
    """Add InChI keys from the chemical properties file to the xref object."""

    # read the file
    inchi_keys = {}
    with open(join(data_dir, files[file_key]), "r") as f:
        for line in f.readlines():
            if line.strip().startswith("#") or line.strip() == "":
                continue
            split_line = [x.strip() for x in line.split("\t")]
            # no inchi
            inchi_key = split_line[8].strip()
            if inchi_key == "" or inchi_key == "NA":
                continue
            inchi_keys[split_line[0]] = inchi_key

    for bigg_id, val in chemical_xref.items():
        for mnx_id in val["metanetx.chemical"]:
            inchi_key = inchi_keys.get(mnx_id, None)
            if inchi_key is not None:
                val["inchi_key"] = [inchi_key]

    return chemical_xref


def add_ec_numbers(file_key, reaction_xref):
    """Add EC numbers from the reaction properties file to the xref object."""

    # read the file
    ec_numbers = defaultdict(set)
    with open(join(data_dir, files[file_key]), "r") as f:
        for line in f.readlines():
            if line.strip().startswith("#") or line.strip() == "":
                continue
            split_line = [x.strip() for x in line.split("\t")]
            # no ec number
            if split_line[4].strip() == "":
                continue
            for ec in [x.strip() for x in split_line[4].split(";")]:
                # ec_numbers[MNX_ID] = EC
                ec_numbers[split_line[0]].add(ec)

    for bigg_id, val in reaction_xref.items():
        if not "metanetx.reaction" in val:
            continue
        for mnx_id in val["metanetx.reaction"]:
            if not mnx_id in ec_numbers:
                continue
            if not "ec-code" in val:
                val["ec-code"] = []
            val["ec-code"] += ec_numbers[mnx_id]

    return reaction_xref


def parse_xref(file_key, ref_type):
    """Read an xref file and generate a dict like this:

    { bigg_id: { external_db_tranlated: [values] } }

    """

    bigg_to_metanetx = {}
    metanetx_to_ref = defaultdict(lambda: defaultdict(list))

    # read the file
    with open(join(data_dir, files[file_key]), "r") as f:
        for line in f.readlines():
            if line.strip().startswith("#") or line.strip() == "":
                continue
            split_line = [x.strip() for x in line.split("\t")]
            strip_line = [x.strip() for x in split_line[0].split(":", 1)]
            try:
                ref, val = strip_line[:2]
            except:
                continue
            if ref == "bigg":
                bigg_to_metanetx[val] = split_line[1]
            else:
                # look for the db in the translation dict
                trans = db_translation[ref_type].get(ref, None)
                if trans is None:
                    # no translation
                    ref_tr = ref
                elif hasattr(trans, "__call__"):
                    # if it's a function
                    ref_tr, val = trans(val)
                else:
                    # translation
                    ref_tr = trans
                metanetx_to_ref[split_line[1]][ref_tr].append(val)

    # make the dictionary and add metanetx ref
    mnx_ref_id = (
        "metanetx.chemical" if ref_type == "metabolite" else "metanetx.reaction"
    )
    return {
        bigg: dict(metanetx_to_ref[mnx], **{mnx_ref_id: [mnx]})
        for bigg, mnx in bigg_to_metanetx.items()
    }


def print_missing_metabolite_refs(session):
    """Print any metabolites with no external database ID, by model."""
    print("Looking for metabolites with no linkout")
    mets_with_source_db = (
        session.query(Component.id)
        .join(Synonym, Synonym.ome_id == Component.id)
        .join(DataSource, DataSource.id == Synonym.data_source_id)
        .filter(DataSource.url_prefix is not None)
        .filter(DataSource.name != "metanetx.chemical")
    )
    mets_no_source_db = (
        session.query(Model.bigg_id, Component.bigg_id)
        .join(
            ModelCompartmentalizedComponent,
            ModelCompartmentalizedComponent.model_id == Model.id,
        )
        .join(
            CompartmentalizedComponent,
            CompartmentalizedComponent.id
            == ModelCompartmentalizedComponent.compartmentalized_component_id,
        )
        .join(Component, Component.id == CompartmentalizedComponent.component_id)
        .filter(~Component.id.in_(mets_with_source_db))
        .order_by(Model.bigg_id)
    )
    by_model = defaultdict(list)
    for model_bigg_id, met_bigg_id in mets_no_source_db:
        by_model[model_bigg_id].append(met_bigg_id)
    for model_bigg_id, l in by_model.items():
        print("Warning: Metabolites with no linkout in model %s" % model_bigg_id)
        print(", ".join(l))
    print("Finished")


if __name__ == "__main__":
    main()
